{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Data_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericae9/Autonomous-Vehicle-Object-Detection/blob/main/CV_Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snNdfSXYPB9c"
      },
      "source": [
        "This notebook contains the code to process the [Berkeley DeepDrive Dataset](https://arxiv.org/abs/1805.04687), splitting the dataset into training, validation, and test datasets, and formatting the labels for the [PyTorch Faster-RCNN](http://pytorch.org/vision/stable/models.html#object-detection-instance-segmentation-and-person-keypoint-detection) and [YOLOv4](https://github.com/AlexeyAB/darknet) models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFxsI9W_5PDv"
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "import random\n",
        "import torch\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD7Yi15IO1vX"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsfzj1WKQtW"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN9DovUk6QOy"
      },
      "source": [
        "## Split the data into train, validation, and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvLgJ6SsOekR"
      },
      "source": [
        "# Edit the file path below to go to the location of the images.\n",
        "image_file_path = '/content/drive/MyDrive/CV_Project/images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQNrBJHE6UGW"
      },
      "source": [
        "all_images = []\n",
        "for image_name in glob.iglob(image_file_path + '*'):\n",
        "    all_images.append(image_name)\n",
        "random.shuffle(all_images)\n",
        "num_training_images = int(len(all_images) * 0.7)\n",
        "num_val_images = int(len(all_images) * 0.1)\n",
        "training_images = all_images[:num_training_images]\n",
        "val_images = all_images[num_training_images:num_training_images + num_val_images]\n",
        "test_images = all_images[num_training_images + num_val_images:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dUP3wPLGhgJ"
      },
      "source": [
        "## Move images into subfolders to help prevent a Google Drive Timeout Error, which can occur when you try to open a file, in this case an image, in a folder that contains many files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmf7ML2WIlxW"
      },
      "source": [
        "def create_image_folders(image_dir, images, data_split):\n",
        "    \"\"\"\n",
        "    Copies the images in the given directory to subfolders,\n",
        "    placing about 1000 images in each subfolder.\n",
        "\n",
        "    Args:\n",
        "      image_dir: Name of top folder, which will contain subfolders with images.\n",
        "      images: List of current locations of the images to copy.\n",
        "      data_split: train, val, or test, depending on what dataset the given\n",
        "      images are in.\n",
        "    \n",
        "    Returns:\n",
        "      Dictionary where the key is the original image location and the value\n",
        "      is a tuple of the form (new image location, data_split).\n",
        "    \"\"\"\n",
        "    image_num = 0\n",
        "    cur_dir_num = 0\n",
        "    os.mkdir(image_dir + str(cur_dir_num))\n",
        "    image_locations = dict()\n",
        "    for image in images:\n",
        "        if int(image_num / 1000) != cur_dir_num:\n",
        "            cur_dir_num = int(image_num / 1000)\n",
        "            os.mkdir(image_dir + str(cur_dir_num))\n",
        "        new_dir = image_dir + str(cur_dir_num) + '/'\n",
        "        image_locations[image] = (new_dir, data_split)\n",
        "        file_name = os.path.basename(image)\n",
        "        copyfile(image, new_dir + file_name)\n",
        "        image_num += 1\n",
        "    return image_locations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG-qGJuUK3ch"
      },
      "source": [
        "# Edit the file paths below to go to the folders the train, validation, and test\n",
        "# images should be saved in.\n",
        "all_image_locations = create_image_folders('/content/drive/MyDrive/CV_Project/training_images/train', training_images, 'train')\n",
        "all_image_locations.update(create_image_folders('/content/drive/MyDrive/CV_Project/val_images/val', val_images, 'val'))\n",
        "all_image_locations.update(create_image_folders('/content/drive/MyDrive/CV_Project/test_images/test', test_images, 'test'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1rePyxCScOt"
      },
      "source": [
        "## Get a list of object classes (categories)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjESHwn4QbMj"
      },
      "source": [
        "categories = []\n",
        "# Edit the file path below to go to the original labels file for the training set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_train.json', 'rb') as original_train_labels_file:\n",
        "    original_train_labels = json.load(original_train_labels_file)\n",
        "for index, image_obj in enumerate(original_train_labels):\n",
        "    if 'labels' not in image_obj:\n",
        "        continue\n",
        "    else:\n",
        "        for bounding_box in image_obj['labels']:\n",
        "            categories.append(bounding_box['category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6fUMLLiRYMe"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the validation set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_val.json', 'rb') as original_val_labels_file:\n",
        "    original_val_labels = json.load(original_val_labels_file)\n",
        "for image_obj in original_val_labels:\n",
        "    if 'labels' not in image_obj:\n",
        "        continue\n",
        "    else:\n",
        "        for bounding_box in image_obj['labels']:\n",
        "            categories.append(bounding_box['category'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idNICDnbQ8Wo"
      },
      "source": [
        "set(categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNgWyxdRRzLR"
      },
      "source": [
        "## Format the labels for Faster R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQ5_z_uE1TO"
      },
      "source": [
        "### Create a dictionary with class label as the key and index as the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LehWIXfRE3bo"
      },
      "source": [
        "label_to_index = {\n",
        "    'background': 0,\n",
        "    'pedestrian': 1,\n",
        "    'rider': 2,\n",
        "    'car': 3,\n",
        "    'truck': 4,\n",
        "    'bus': 5,\n",
        "    'train': 6,\n",
        "    'motorcycle': 7,\n",
        "    'bicycle': 8,\n",
        "    'traffic light': 9,\n",
        "    'traffic sign': 10,\n",
        "    'other person': 11,\n",
        "    'other vehicle': 12,\n",
        "    'trailer': 13\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVwWglaMPwIk"
      },
      "source": [
        "### Create a dictionary with image name as the key and (image location, data split) as the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDtQM5mwRNAK"
      },
      "source": [
        "all_image_locations = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzp4SeAhQDWY"
      },
      "source": [
        "# Edit the file path below to go to the folder containing the training set.\n",
        "for train_image_folder in glob.iglob('/content/drive/MyDrive/CV_Project/training_images/*'):\n",
        "    print('On folder:', train_image_folder)\n",
        "    for train_image in glob.iglob(train_image_folder + '/*'):\n",
        "        all_image_locations[os.path.basename(train_image)] = (train_image, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkLI5B82ROi3"
      },
      "source": [
        "# Edit the file path below to go to the folder containing the validation set.\n",
        "for val_image_folder in glob.iglob('/content/drive/MyDrive/CV_Project/val_images/*'):\n",
        "    print('On folder:', val_image_folder)\n",
        "    for val_image in glob.iglob(val_image_folder + '/*'):\n",
        "        all_image_locations[os.path.basename(val_image)] = (val_image, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvAOC6aHRO24"
      },
      "source": [
        "# Edit the file path below to go to the folder containing the test set.\n",
        "for test_image_folder in glob.iglob('/content/drive/MyDrive/CV_Project/test_images/*'):\n",
        "    print('On folder:', test_image_folder)\n",
        "    for test_image in glob.iglob(test_image_folder + '/*'):\n",
        "        all_image_locations[os.path.basename(test_image)] = (test_image, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OoxjrHS7b21"
      },
      "source": [
        "### Format the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SOYTYU7_h7g"
      },
      "source": [
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "image_id = 0\n",
        "# Edit the file path below to go to the original labels file for the training set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_train.json', 'rb') as original_train_labels_file:\n",
        "    original_train_labels = json.load(original_train_labels_file)\n",
        "for image_obj in original_train_labels:\n",
        "    cur_label = {\n",
        "        'image_id': torch.tensor([image_id])\n",
        "    }\n",
        "    boxes = []\n",
        "    areas = []\n",
        "    new_image_location, image_data_split = all_image_locations[image_obj['name']]\n",
        "    if 'labels' in image_obj:\n",
        "        cur_label['iscrowd'] = torch.zeros((len(image_obj['labels']),), dtype=torch.int64)\n",
        "        cur_label['labels'] = torch.zeros((len(image_obj['labels']),), dtype=torch.int64)\n",
        "        for cur_index, bounding_box in enumerate(image_obj['labels']):\n",
        "            boxes.append([bounding_box['box2d']['x1'], bounding_box['box2d']['y1'],\n",
        "                          bounding_box['box2d']['x2'], bounding_box['box2d']['y2']])\n",
        "            cur_area = (bounding_box['box2d']['x2'] - bounding_box['box2d']['x1']) * (bounding_box['box2d']['y2'] - bounding_box['box2d']['y1'])\n",
        "            areas.append(cur_area)\n",
        "            cur_label['labels'][cur_index] = label_to_index[bounding_box['category']]\n",
        "    else:\n",
        "        cur_label['iscrowd'] = torch.zeros((1,), dtype=torch.int64)\n",
        "        cur_label['labels'] = torch.tensor([label_to_index['background']], dtype=torch.int64)\n",
        "        cur_image = Image.open(new_image_location)\n",
        "        image_width, image_height = cur_image.size\n",
        "        boxes.append([0.5, 0.5, image_width - 0.5, image_height - 0.5])\n",
        "        areas.append(image_width * image_height)\n",
        "    cur_label['boxes'] = torch.tensor(boxes)\n",
        "    cur_label['area'] = torch.tensor(areas)\n",
        "    if image_data_split == 'train':\n",
        "        train_labels.append((new_image_location, cur_label))\n",
        "    elif image_data_split == 'val':\n",
        "        val_labels.append((new_image_location, cur_label))\n",
        "    else:\n",
        "        test_labels.append((new_image_location, cur_label))\n",
        "    image_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPKHhqwPuWY"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the validation set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_val.json', 'rb') as original_val_labels_file:\n",
        "    original_val_labels = json.load(original_val_labels_file)\n",
        "for image_obj in original_val_labels:\n",
        "    cur_label = {\n",
        "        'image_id': torch.tensor([image_id])\n",
        "    }\n",
        "    boxes = []\n",
        "    areas = []\n",
        "    new_image_location, image_data_split = all_image_locations[image_obj['name']]\n",
        "    if 'labels' in image_obj:\n",
        "        cur_label['iscrowd'] = torch.zeros((len(image_obj['labels']),), dtype=torch.int64)\n",
        "        cur_label['labels'] = torch.zeros((len(image_obj['labels']),), dtype=torch.int64)\n",
        "        for cur_index, bounding_box in enumerate(image_obj['labels']):\n",
        "            boxes.append([bounding_box['box2d']['x1'], bounding_box['box2d']['y1'],\n",
        "                          bounding_box['box2d']['x2'], bounding_box['box2d']['y2']])\n",
        "            cur_area = (bounding_box['box2d']['x2'] - bounding_box['box2d']['x1']) * (bounding_box['box2d']['y2'] - bounding_box['box2d']['y1'])\n",
        "            areas.append(cur_area)\n",
        "            cur_label['labels'][cur_index] = label_to_index[bounding_box['category']]\n",
        "    else:\n",
        "        cur_label['iscrowd'] = torch.zeros((1,), dtype=torch.int64)\n",
        "        cur_label['labels'] = torch.tensor([label_to_index['background']], dtype=torch.int64)\n",
        "        cur_image = Image.open(new_image_location)\n",
        "        image_width, image_height = cur_image.size\n",
        "        boxes.append([0.5, 0.5, image_width - 0.5, image_height - 0.5])\n",
        "        areas.append(image_width * image_height)\n",
        "    cur_label['boxes'] = torch.tensor(boxes)\n",
        "    cur_label['area'] = torch.tensor(areas)\n",
        "    if image_data_split == 'train':\n",
        "        train_labels.append((new_image_location, cur_label))\n",
        "    elif image_data_split == 'val':\n",
        "        val_labels.append((new_image_location, cur_label))\n",
        "    else:\n",
        "        test_labels.append((new_image_location, cur_label))\n",
        "    image_id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG4Nlk0cGFUe"
      },
      "source": [
        "faster_rcnn_labels = {\n",
        "    'train_labels': train_labels,\n",
        "    'val_labels': val_labels,\n",
        "    'test_labels': test_labels\n",
        "}\n",
        "# Edit the file path below to go to the location where the labels for Faster\n",
        "# R-CNN should be stored.\n",
        "pickle.dump(faster_rcnn_labels, open('/content/drive/MyDrive/CV_Project/faster_rcnn_labels.p', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBE_9dHR3Q_"
      },
      "source": [
        "## Format the labels for YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5vxWsqlSI-2"
      },
      "source": [
        "### Create a dictionary with class label as the key and index as the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKYZbRZtR5B3"
      },
      "source": [
        "label_to_index = {\n",
        "    'pedestrian': 0,\n",
        "    'rider': 1,\n",
        "    'car': 2,\n",
        "    'truck': 3,\n",
        "    'bus': 4,\n",
        "    'train': 5,\n",
        "    'motorcycle': 6,\n",
        "    'bicycle': 7,\n",
        "    'traffic light': 8,\n",
        "    'traffic sign': 9,\n",
        "    'other person': 10,\n",
        "    'other vehicle': 11,\n",
        "    'trailer': 12\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8gV4tpXG5XB"
      },
      "source": [
        "### Create a dictionary with image name as the key and (image location, data split) as the value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQskukVeKgCQ"
      },
      "source": [
        "# Edit the file path below to go the build/darknet/x64/data folder in the\n",
        "# darknet repository. Before running this cell, clone the darknet repo\n",
        "# from https://github.com/AlexeyAB/darknet\n",
        "darknet_path = '/content/drive/MyDrive/CV_Project/darknet/build/darknet/x64/data/'\n",
        "all_image_locations = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EppHgp5tHCrX"
      },
      "source": [
        "for train_image_folder in glob.iglob(darknet_path + 'obj/training_images/*'):\n",
        "    print('On folder:', train_image_folder)\n",
        "    for train_image in glob.iglob(train_image_folder + '/*.jpg'):\n",
        "        image_name = os.path.basename(train_image)\n",
        "        all_image_locations[image_name] = (train_image, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Im4XeEHDAf"
      },
      "source": [
        "for val_image_folder in glob.iglob(darknet_path + 'obj/val_images/*'):\n",
        "    print('On folder:', val_image_folder)\n",
        "    for val_image in glob.iglob(val_image_folder + '/*.jpg'):\n",
        "        image_name = os.path.basename(val_image)\n",
        "        all_image_locations[image_name] = (val_image, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSdr3sYHFtp"
      },
      "source": [
        "for test_image_folder in glob.iglob(darknet_path + 'obj/test_images/*'):\n",
        "    print('On folder:', test_image_folder)\n",
        "    for test_image in glob.iglob(test_image_folder + '/*.jpg'):\n",
        "        image_name = os.path.basename(test_image)\n",
        "        all_image_locations[image_name] = (test_image, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjoE_fEPZ546"
      },
      "source": [
        "### Create a txt file for each image, containing the bounding box information and corresponding class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3O7zm3qCJ7A"
      },
      "source": [
        "train_image_locations = []\n",
        "val_image_locations = []\n",
        "test_image_locations = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d9vl0KnVPTL"
      },
      "source": [
        "# Edit the file path below to go to the file path for any image in the training,\n",
        "# validation, or test set.\n",
        "with Image.open('/content/drive/MyDrive/CV_Project/darknet/build/darknet/x64/data/obj/training_images/train12/0ac3cbf4-73c76d25.jpg') as cur_image:\n",
        "    image_width, image_height = cur_image.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVxA4n7rZ78e"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the training set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_train.json', 'rb') as original_train_labels_file:\n",
        "    original_train_labels = json.load(original_train_labels_file)\n",
        "image_num = 0\n",
        "already_done = 0\n",
        "for image_obj in original_train_labels:\n",
        "    image_num += 1\n",
        "    if image_num % 1000 == 0:\n",
        "        print('Completed', image_num, 'images')\n",
        "    if image_obj['name'] not in all_image_locations:\n",
        "        continue\n",
        "    image_location, data_split = all_image_locations[image_obj['name']]\n",
        "    cur_file_name = image_location[:image_location.index('.')] + '.txt'\n",
        "    if data_split == 'train':\n",
        "        train_image_locations.append(image_location)\n",
        "    elif data_split == 'val':\n",
        "        val_image_locations.append(image_location)\n",
        "    else:\n",
        "        test_image_locations.append(image_location)\n",
        "    if os.path.isfile(cur_file_name):\n",
        "        already_done += 1\n",
        "        continue\n",
        "    time.sleep(0.05)\n",
        "    if 'labels' in image_obj:\n",
        "        boxes = []\n",
        "        for cur_index, bounding_box in enumerate(image_obj['labels']):\n",
        "            cur_label = label_to_index[bounding_box['category']]\n",
        "            box_width = bounding_box['box2d']['x2'] - bounding_box['box2d']['x1']\n",
        "            box_height = bounding_box['box2d']['y2'] - bounding_box['box2d']['y1']\n",
        "            x_center_abs = bounding_box['box2d']['x1'] + (box_width / 2)\n",
        "            x_center_rel = x_center_abs / image_width\n",
        "            y_center_abs = bounding_box['box2d']['y1'] + (box_height / 2)\n",
        "            y_center_rel = y_center_abs / image_height\n",
        "            rel_width = box_width / image_width\n",
        "            rel_height = box_height / image_height\n",
        "            cur_box = [str(cur_label), str(x_center_rel), str(y_center_rel), str(rel_width), str(rel_height)]\n",
        "            boxes.append(' '.join(cur_box))\n",
        "        cur_file_contents = '\\n'.join(boxes)\n",
        "    else:\n",
        "        cur_file_contents = ''\n",
        "    with open(cur_file_name, 'w') as cur_image_file:\n",
        "        cur_image_file.write(cur_file_contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_PwQIPCP7vw"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the validation set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_val.json', 'rb') as original_val_labels_file:\n",
        "    original_val_labels = json.load(original_val_labels_file)\n",
        "image_num = 0\n",
        "for image_obj in original_val_labels:\n",
        "    image_num += 1\n",
        "    if image_num % 1000 == 0:\n",
        "        print('Completed', image_num, 'images')\n",
        "    if image_obj['name'] not in all_image_locations:\n",
        "        continue\n",
        "    image_location, data_split = all_image_locations[image_obj['name']]\n",
        "    cur_file_name = image_location[:image_location.index('.')] + '.txt'\n",
        "    if data_split == 'train':\n",
        "        train_image_locations.append(image_location)\n",
        "    elif data_split == 'val':\n",
        "        val_image_locations.append(image_location)\n",
        "    else:\n",
        "        test_image_locations.append(image_location)\n",
        "    if os.path.isfile(cur_file_name):\n",
        "        already_done += 1\n",
        "        continue\n",
        "    time.sleep(0.05)\n",
        "    if 'labels' in image_obj:\n",
        "        boxes = []\n",
        "        for cur_index, bounding_box in enumerate(image_obj['labels']):\n",
        "            cur_label = label_to_index[bounding_box['category']]\n",
        "            box_width = bounding_box['box2d']['x2'] - bounding_box['box2d']['x1']\n",
        "            box_height = bounding_box['box2d']['y2'] - bounding_box['box2d']['y1']\n",
        "            x_center_abs = bounding_box['box2d']['x1'] + (box_width / 2)\n",
        "            x_center_rel = x_center_abs / image_width\n",
        "            y_center_abs = bounding_box['box2d']['y1'] + (box_height / 2)\n",
        "            y_center_rel = y_center_abs / image_height\n",
        "            rel_width = box_width / image_width\n",
        "            rel_height = box_height / image_height\n",
        "            cur_box = [str(cur_label), str(x_center_rel), str(y_center_rel), str(rel_width), str(rel_height)]\n",
        "            boxes.append(' '.join(cur_box))\n",
        "        cur_file_contents = '\\n'.join(boxes)\n",
        "    else:\n",
        "        cur_file_contents = ''\n",
        "    with open(cur_file_name, 'w') as cur_image_file:\n",
        "        cur_image_file.write(cur_file_contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlwNvoyJmLuY"
      },
      "source": [
        "print('Number of txt files already created:', already_done)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeUczjgJRGTW"
      },
      "source": [
        "# Create train.txt with the location of each image in the training set.\n",
        "with open(darknet_path + 'train.txt', 'w') as train_file:\n",
        "    train_file_contents = '\\n'.join(train_image_locations)\n",
        "    train_file.write(train_file_contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcLCJJTwRH4v"
      },
      "source": [
        "# Create val.txt with the location of each image in the validation set.\n",
        "with open(darknet_path + 'val.txt', 'w') as val_file:\n",
        "    val_file_contents = '\\n'.join(val_image_locations)\n",
        "    val_file.write(val_file_contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVTiwLSURJmv"
      },
      "source": [
        "# Create test.txt with the location of each image in the test set.\n",
        "with open(darknet_path + 'test.txt', 'w') as test_file:\n",
        "    test_file_contents = '\\n'.join(test_image_locations)\n",
        "    test_file.write(test_file_contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKPXWffOknJz"
      },
      "source": [
        "## Get dataset info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hynert-skosp"
      },
      "source": [
        "num_objects = 0\n",
        "num_images = 0\n",
        "# For each class, the number of times an object from that class\n",
        "# appears in an image.\n",
        "num_objects_per_class = {\n",
        "    'pedestrian': 0,\n",
        "    'rider': 0,\n",
        "    'car': 0,\n",
        "    'truck': 0,\n",
        "    'bus': 0,\n",
        "    'train': 0,\n",
        "    'motorcycle': 0,\n",
        "    'bicycle': 0,\n",
        "    'traffic light': 0,\n",
        "    'traffic sign': 0,\n",
        "    'other person': 0,\n",
        "    'other vehicle': 0,\n",
        "    'trailer': 0\n",
        "}\n",
        "# For each class, the number of images that contain at least one object\n",
        "# from that class.\n",
        "num_images_with_object_class = {\n",
        "    'none': 0,\n",
        "    'pedestrian': 0,\n",
        "    'rider': 0,\n",
        "    'car': 0,\n",
        "    'truck': 0,\n",
        "    'bus': 0,\n",
        "    'train': 0,\n",
        "    'motorcycle': 0,\n",
        "    'bicycle': 0,\n",
        "    'traffic light': 0,\n",
        "    'traffic sign': 0,\n",
        "    'other person': 0,\n",
        "    'other vehicle': 0,\n",
        "    'trailer': 0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWFMitSkxC_"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the training set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_train.json', 'rb') as original_train_labels_file:\n",
        "    original_train_labels = json.load(original_train_labels_file)\n",
        "for image_obj in original_train_labels:\n",
        "    num_images += 1\n",
        "    if 'labels' not in image_obj:\n",
        "        num_images_with_object_class['none'] += 1\n",
        "    else:\n",
        "        cur_box_classes = [box['category'] for box in image_obj['labels']]\n",
        "        num_objects += len(cur_box_classes)\n",
        "        for cur_class in cur_box_classes:\n",
        "            num_objects_per_class[cur_class] += 1\n",
        "        cur_box_class_set = set(cur_box_classes)\n",
        "        for cur_class in cur_box_class_set:\n",
        "            num_images_with_object_class[cur_class] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63IjdF7Pk5XT"
      },
      "source": [
        "# Edit the file path below to go to the original labels file for the validation set.\n",
        "with open('/content/drive/MyDrive/CV_Project/det_val.json', 'rb') as original_val_labels_file:\n",
        "    original_val_labels = json.load(original_val_labels_file)\n",
        "for image_obj in original_val_labels:\n",
        "    num_images += 1\n",
        "    if 'labels' not in image_obj:\n",
        "        num_images_with_object_class['none'] += 1\n",
        "    else:\n",
        "        cur_box_classes = [box['category'] for box in image_obj['labels']]\n",
        "        num_objects += len(cur_box_classes)\n",
        "        for cur_class in cur_box_classes:\n",
        "            num_objects_per_class[cur_class] += 1\n",
        "        cur_box_class_set = set(cur_box_classes)\n",
        "        for cur_class in cur_box_class_set:\n",
        "            num_images_with_object_class[cur_class] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztxVYMIuk9Ke"
      },
      "source": [
        "print('Total number of images:', num_images)\n",
        "print('Total number of objects:', num_objects)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lUIjyqhk-vF"
      },
      "source": [
        "avg_objs_per_image = round(num_objects / num_images)\n",
        "print('Average number of objects per image:', avg_objs_per_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ro3ih4lAdK"
      },
      "source": [
        "print('Total number of objects for each class:')\n",
        "for obj_class in num_objects_per_class:\n",
        "    print(obj_class, ':', num_objects_per_class[obj_class])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to_gLz2ZlCaV"
      },
      "source": [
        "print('For each class, number of images that contain at least one object from that class:')\n",
        "for obj_class in num_images_with_object_class:\n",
        "    print(obj_class, ':', num_images_with_object_class[obj_class])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}